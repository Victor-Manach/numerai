{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Victor-Manach/numerai/blob/main/lgbm_walk_forward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTSZYyg4qMnX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkq0SXrzr1pj",
        "outputId": "a8420271-4dd1-403f-c8ae-ff06f7e8afb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q numerapi pandas pyarrow matplotlib lightgbm==4.0.0 xgboost==1.7.5 scikit-learn cloudpickle==2.2.1 scipy==1.10.1 umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuOqGZZlsn7l"
      },
      "outputs": [],
      "source": [
        "!pip install -q --no-deps numerai-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e3fO1Qk2Nzp",
        "outputId": "e7a12ad5-be8e-40e6-ceb3-842af8ea803e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from numerapi import NumerAPI\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from numerai_tools.scoring import numerai_corr\n",
        "import cloudpickle\n",
        "import lightgbm as lgb\n",
        "\n",
        "from typing import List, Dict, Any, Optional, Callable\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "import pyarrow.dataset as ds\n",
        "import pyarrow as pa\n",
        "\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaeGSZ-m39ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951c49a8-1efb-4055-9f33-fe0f89868dd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def has_gpu():\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    return not gpu_info.find('failed') >= 0\n",
        "\n",
        "gpu_available = has_gpu()\n",
        "gpu_available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDWYNuv3ry1Z"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9T2ICJEPd6l"
      },
      "outputs": [],
      "source": [
        "def format_era_list(era_list:List[int]) -> List[str]:\n",
        "    return [f\"{era:04d}\" for era in era_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHhe7mTyrxV3"
      },
      "outputs": [],
      "source": [
        "def get_training_steps(\n",
        "    total_eras: int,\n",
        "    eras_per_chunk: int,\n",
        "    purge_eras: int,\n",
        "    eras_overlap: int = 0,\n",
        "    increment_start_era: bool = False\n",
        ") -> List[Dict[str, Any]]:\n",
        "    steps = []\n",
        "    train_start_era = 1\n",
        "    train_window_size = eras_per_chunk - purge_eras\n",
        "    train_end_era = train_start_era + train_window_size - 1\n",
        "\n",
        "    while train_start_era <= total_eras:\n",
        "        if train_end_era > total_eras:\n",
        "            train_end_era = total_eras\n",
        "\n",
        "        purge_start_era = train_end_era + 1\n",
        "        purge_end_era = train_end_era + purge_eras\n",
        "\n",
        "        # Adjust purge_end_era if it exceeds total_eras\n",
        "        if purge_end_era > total_eras:\n",
        "            purge_end_era = total_eras\n",
        "\n",
        "        validation_start_era = purge_end_era + 1\n",
        "        validation_end_era = validation_start_era + eras_per_chunk - 1\n",
        "\n",
        "        # Adjust validation_start_era and validation_end_era if they exceed total_eras\n",
        "        if validation_start_era > total_eras:\n",
        "            validation_eras = []\n",
        "        else:\n",
        "            if validation_end_era > total_eras:\n",
        "                validation_end_era = total_eras\n",
        "            validation_eras = list(range(validation_start_era, validation_end_era + 1))\n",
        "\n",
        "        # Create lists of eras for training and purge\n",
        "        train_eras = list(range(train_start_era, train_end_era + 1))\n",
        "        purge_eras_list = list(range(purge_start_era, purge_end_era + 1))\n",
        "\n",
        "        # Append phase details to steps list\n",
        "        steps.append({\n",
        "            'train_eras': format_era_list(train_eras),\n",
        "            'validation_eras': format_era_list(validation_eras),\n",
        "            'train_end_era': train_end_era,\n",
        "            'validation_start_era': validation_start_era if validation_eras else None,\n",
        "            'validation_end_era': validation_end_era if validation_eras else None,\n",
        "            'purge_eras': format_era_list(purge_eras_list)\n",
        "        })\n",
        "\n",
        "        # Check if we've reached the end of the data\n",
        "        if train_end_era >= total_eras:\n",
        "            break  # No more data to process\n",
        "\n",
        "        if increment_start_era:\n",
        "            # Move both start and end of the training window forward\n",
        "            train_start_era += eras_per_chunk - eras_overlap\n",
        "            train_end_era = train_start_era + train_window_size - 1\n",
        "        else:\n",
        "            # Only move the end of the training window forward\n",
        "            train_end_era += eras_per_chunk\n",
        "\n",
        "    return steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVI-sLQPsHSa"
      },
      "outputs": [],
      "source": [
        "def downsample_dataset(dataset, columns_to_read:List[str], n:int, eras_to_embargo:Optional[List[str]]=None) -> pd.DataFrame:\n",
        "    eras = dataset.to_table(columns=['era']).column('era').to_pandas()\n",
        "    unique_eras = eras.unique().tolist()\n",
        "    if eras_to_embargo:\n",
        "        unique_eras = [era_id for era_id in unique_eras if era_id not in eras_to_embargo]\n",
        "    downsampled_eras = unique_eras[::n]\n",
        "    filtered_eras = ds.field('era').isin(downsampled_eras)\n",
        "\n",
        "    downsampled_table = dataset.to_table(filter=filtered_eras, columns=columns_to_read)\n",
        "\n",
        "    return downsampled_table.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2SF7efjsHSb"
      },
      "outputs": [],
      "source": [
        "def save_predict_func_to_pkl_file(\n",
        "    pkl_file_path:Path,\n",
        "    predict_func:Callable[[pd.DataFrame],pd.DataFrame]\n",
        "  ) -> None:\n",
        "\n",
        "  p = cloudpickle.dumps(predict_func)\n",
        "  with open(pkl_file_path, \"wb\") as f:\n",
        "    f.write(p)\n",
        "\n",
        "  return None\n",
        "\n",
        "def save_predict_func_to_file_and_check_on_data(\n",
        "    pkl_file_path:Path,\n",
        "    predict_func:Callable[[pd.DataFrame],pd.DataFrame],\n",
        "    input_data:pd.DataFrame\n",
        "  ) -> None:\n",
        "\n",
        "  save_predict_func_to_pkl_file(pkl_file_path, predict_func)\n",
        "  result = predict_func(input_data)\n",
        "\n",
        "  with open(pkl_file_path, \"rb\") as f:\n",
        "    loaded_predict:Callable[[pd.DataFrame], pd.DataFrame] = cloudpickle.load(f)\n",
        "\n",
        "  loaded_result = loaded_predict(input_data)\n",
        "\n",
        "  pd.testing.assert_frame_equal(result, loaded_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZDvX4kLsHSc"
      },
      "outputs": [],
      "source": [
        "def compute_sample_weights(target: pd.Series) -> pd.Series:\n",
        "    value_counts = target.value_counts(normalize=True)\n",
        "\n",
        "    inverse_freq = 1.0 / value_counts\n",
        "\n",
        "    weights = target.map(inverse_freq)\n",
        "    weights = weights / weights.sum() * len(target)\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4OcBzIUsHSd"
      },
      "outputs": [],
      "source": [
        "def train_model_with_walk_forward(\n",
        "        lgb_params,\n",
        "        train_dataset,\n",
        "        training_steps,\n",
        "        columns_to_read,\n",
        "        feature_set,\n",
        "        target_col,\n",
        "        path_to_save_model,\n",
        "        model_name,\n",
        "        save_model:bool=True\n",
        "    ):\n",
        "\n",
        "    pbar = tqdm(training_steps, desc='Training Phases', total=len(training_steps))\n",
        "\n",
        "    model = lgb.LGBMRegressor(**lgb_params)\n",
        "    previous_model = None\n",
        "\n",
        "    for step in pbar:\n",
        "        train_eras = step['train_eras']\n",
        "        validation_eras = step['validation_eras']\n",
        "        purge_eras_range = step['purge_eras']\n",
        "\n",
        "        df_train = train_dataset.to_table(filter=ds.field('era').isin(train_eras), columns=columns_to_read).to_pandas()\n",
        "\n",
        "\n",
        "        X_train = df_train[feature_set]\n",
        "        y_train = df_train[target_col]\n",
        "\n",
        "        sample_weight = compute_sample_weights(df_train[target_col])\n",
        "\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            sample_weight=sample_weight,\n",
        "            init_model=previous_model\n",
        "        )\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        df_train['y_pred'] = y_train_pred\n",
        "\n",
        "        per_era_train_corr = df_train.groupby(\"era\").apply(\n",
        "            lambda x: numerai_corr(x[[\"y_pred\"]].dropna(), x[target_col].dropna()),\n",
        "            include_groups=False\n",
        "        )\n",
        "        train_corr = per_era_train_corr.sum().values[0]\n",
        "\n",
        "        if validation_eras:\n",
        "            df_validation = train_dataset.to_table(filter=ds.field('era').isin(validation_eras), columns=columns_to_read).to_pandas()\n",
        "            X_valid = df_validation[feature_set]\n",
        "            y_valid = df_validation[target_col]\n",
        "\n",
        "            y_valid_pred = model.predict(X_valid)\n",
        "            df_validation['y_pred'] = y_valid_pred\n",
        "\n",
        "            per_era_valid_corr = df_validation.groupby(\"era\").apply(\n",
        "                lambda x: numerai_corr(x[[\"y_pred\"]].dropna(), x[target_col].dropna()),\n",
        "                include_groups=False\n",
        "            )\n",
        "            valid_corr = per_era_valid_corr.sum().values[0]\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'Train Eras': f\"{train_eras[0]}-{train_eras[-1]}\",\n",
        "                'Purge Eras': f\"{purge_eras_range[0]}-{purge_eras_range[-1]}\",\n",
        "                'Valid Eras': f\"{validation_eras[0]}-{validation_eras[-1]}\",\n",
        "                'Train Corr': f\"{train_corr:.4f}\",\n",
        "                'Valid Corr': f\"{valid_corr:.4f}\"\n",
        "            })\n",
        "\n",
        "            del df_validation, X_valid, y_valid, y_valid_pred, per_era_valid_corr\n",
        "        else:\n",
        "            pbar.set_postfix({\n",
        "                'Train Eras': f\"{train_eras[0]}-{train_eras[-1]}\",\n",
        "                'Train Corr': f\"{train_corr:.4f}\",\n",
        "            })\n",
        "\n",
        "        previous_model = model.booster_\n",
        "\n",
        "\n",
        "        # Clean up\n",
        "        del df_train, X_train, y_train, y_train_pred, per_era_train_corr,\n",
        "        gc.collect()\n",
        "\n",
        "    pbar.close()\n",
        "    if save_model:\n",
        "        model.booster_.save_model(path_to_save_model / f'{model_name}.txt')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "751VneFNsHSd"
      },
      "outputs": [],
      "source": [
        "def compute_and_plot_correlation_with_target(\n",
        "        model,\n",
        "        dataset,\n",
        "        columns_to_read,\n",
        "        feature_set,\n",
        "        target_col:str,\n",
        "        mode:str,\n",
        "        model_name:str,\n",
        "        n=None\n",
        "    ):\n",
        "    print(f'Metrics for model `{model_name}`...')\n",
        "\n",
        "    if n is None:\n",
        "        df = dataset.to_table(columns=columns_to_read)\n",
        "    else:\n",
        "        df = downsample_dataset(dataset, columns_to_read, n=8)\n",
        "\n",
        "    y_pred = model.predict(df[feature_set])\n",
        "    df['y_pred'] = y_pred\n",
        "    print(df['y_pred'].describe())\n",
        "\n",
        "    per_era_corr = df.groupby(\"era\").apply(\n",
        "        lambda x: numerai_corr(x[[\"y_pred\"]].dropna(), x[target_col].dropna()),\n",
        "        include_groups=False\n",
        "    )\n",
        "    per_era_corr.plot(\n",
        "        title=f\"{mode.capitalize()} CORR\",\n",
        "        kind=\"bar\",\n",
        "        figsize=(9, 4),\n",
        "        xticks=[],\n",
        "        legend=False,\n",
        "        snap=False\n",
        "    )\n",
        "\n",
        "    per_era_corr.cumsum().plot(\n",
        "    title=f\"Cumulative {mode.capitalize()} CORR\",\n",
        "    kind=\"line\",\n",
        "    figsize=(8, 4),\n",
        "    legend=False\n",
        "    )\n",
        "    del df, y_pred, per_era_corr\n",
        "\n",
        "    gc.collect()\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaR1enVVggy-"
      },
      "outputs": [],
      "source": [
        "def get_max_era(dataset, data_types):\n",
        "    unique_era_values = set()\n",
        "    era_pattern = re.compile(r'era=([^/\\\\]+)')\n",
        "\n",
        "    for fragment in dataset.get_fragments():\n",
        "        path = fragment.path\n",
        "\n",
        "        if any(f\"data_type={dt}\" in path for dt in data_types):\n",
        "            era_match = era_pattern.search(path)\n",
        "            if era_match:\n",
        "                era_value = era_match.group(1)\n",
        "                unique_era_values.add(int(era_value))\n",
        "\n",
        "    if unique_era_values:\n",
        "        max_era_value = max(unique_era_values)\n",
        "    else:\n",
        "        raise ValueError('No era values found')\n",
        "\n",
        "    return max_era_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uJG6ynTgeFI"
      },
      "outputs": [],
      "source": [
        "def train_validation_split_on_eras(max_era:int, split:float=.75)->tuple[list[str],list[str]]:\n",
        "    all_eras = list(range(max_era + 1))\n",
        "    split_point = int(len(all_eras) * split)\n",
        "    train_eras = [str(era).zfill(4) for era in all_eras[:split_point]]\n",
        "    validation_eras = [str(era).zfill(4) for era in all_eras[split_point:]]\n",
        "\n",
        "    return train_eras, validation_eras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udqQPflxx7a4"
      },
      "outputs": [],
      "source": [
        "def neutralize(\n",
        "    df: pd.DataFrame,\n",
        "    neutralizers: np.ndarray,\n",
        "    proportion: float = 1.0,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Neutralize each column of a given DataFrame by each feature in a given\n",
        "    neutralizers DataFrame. Neutralization uses least-squares regression to\n",
        "    find the orthogonal projection of each column onto the neutralizers, then\n",
        "    subtracts the result from the original predictions.\n",
        "\n",
        "    Arguments:\n",
        "        df: pd.DataFrame - the data with columns to neutralize\n",
        "        neutralizers: pd.DataFrame - the neutralizer data with features as columns\n",
        "        proportion: float - the degree to which neutralization occurs\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame - the neutralized data\n",
        "    \"\"\"\n",
        "    assert not neutralizers.isna().any().any(), \"Neutralizers contain NaNs\"\n",
        "    assert len(df.index) == len(neutralizers.index), \"Indices don't match\"\n",
        "    assert (df.index == neutralizers.index).all(), \"Indices don't match\"\n",
        "    df[df.columns[df.std() == 0]] = np.nan\n",
        "    df_arr = df.values\n",
        "    neutralizer_arr = neutralizers.values\n",
        "    neutralizer_arr = np.hstack(\n",
        "        # add a column of 1s to the neutralizer array in case neutralizer_arr is a single column\n",
        "        (neutralizer_arr, np.array([1] * len(neutralizer_arr)).reshape(-1, 1))\n",
        "    )\n",
        "    inverse_neutralizers = np.linalg.pinv(neutralizer_arr, rcond=1e-6)\n",
        "    adjustments = proportion * neutralizer_arr.dot(inverse_neutralizers.dot(df_arr))\n",
        "    neutral = df_arr - adjustments\n",
        "    return pd.DataFrame(neutral, index=df.index, columns=df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lki0vYhrMOew"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzZrmwr4QdUd"
      },
      "outputs": [],
      "source": [
        "DATA_VERSION = \"v5.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgjitKgpM9g3"
      },
      "outputs": [],
      "source": [
        "TEST_RUN = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owJW3bEeNCkz"
      },
      "outputs": [],
      "source": [
        "# wf = walk_forward\n",
        "MODEL_NAME = 'walk_forward_feature_neutral'\n",
        "MODEL_VERSION = 'large'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRnYy3ecQX4E"
      },
      "outputs": [],
      "source": [
        "PATH_TO_DATA = Path(f'/content/drive/MyDrive/numerai/data/{DATA_VERSION}')\n",
        "PATH_TO_MODELS = Path('/content/drive/MyDrive/numerai/models/')\n",
        "PATH_TO_PREDICT_FUNCS = Path('/content/drive/MyDrive/numerai/predict_funcs/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej_FxPrj2Nzz"
      },
      "source": [
        "## LGB params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7CmaUTC2Nz0"
      },
      "outputs": [],
      "source": [
        "if TEST_RUN:\n",
        "    lgb_params = {\n",
        "        \"n_estimators\": 2,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": 5,\n",
        "        \"num_leaves\": 2**5,\n",
        "        \"colsample_bytree\": 0.1,\n",
        "        \"verbose\": -1,\n",
        "    }\n",
        "else:\n",
        "    max_depth = 6\n",
        "    lgb_params = {\n",
        "        \"n_estimators\": 2_000,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"num_leaves\": 2**max_depth,\n",
        "        \"colsample_bytree\": 0.1,\n",
        "        # \"device\": \"gpu\",\n",
        "        \"verbose\": -1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0AsPa22M7sx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q6HDNi12Nz0"
      },
      "outputs": [],
      "source": [
        "napi = NumerAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s9aLgh2Nz0"
      },
      "outputs": [],
      "source": [
        "all_datasets = napi.list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kycGaoxC2Nz1"
      },
      "outputs": [],
      "source": [
        "features_path = PATH_TO_DATA / 'features.json'\n",
        "target_col = 'target'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bqYsXZB2Nz2"
      },
      "outputs": [],
      "source": [
        "feature_metadata = json.load(open(features_path))\n",
        "feature_sets = feature_metadata[\"feature_sets\"]\n",
        "features = feature_sets['medium'] + feature_sets['rain']\n",
        "to_neutralize_feats = feature_sets['rain']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AXUqxTsP6yD"
      },
      "outputs": [],
      "source": [
        "partitioning = ds.partitioning(\n",
        "    schema=pa.schema([\n",
        "        ('data_type', pa.string()),\n",
        "        ('era', pa.string())\n",
        "    ]),\n",
        "    flavor='hive'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwpvhwFcMXXx"
      },
      "outputs": [],
      "source": [
        "dataset = ds.dataset(PATH_TO_DATA/'pdata', format='parquet', partitioning=partitioning)\n",
        "filtered_dataset = dataset.filter(ds.field('data_type').isin(['train', 'validation']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZeyPg64sHSt",
        "outputId": "6f3a5192-dae2-4cab-acac-7548aa458de1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1138"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "max_era = get_max_era(dataset, {'train', 'validation'})\n",
        "max_era"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsIrwrEGg98s"
      },
      "outputs": [],
      "source": [
        "teras, veras = train_validation_split_on_eras(max_era)\n",
        "# last_train_era = int(teras[-1])\n",
        "last_train_era = max_era"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(teras), len(veras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sEAWfnH1-2f",
        "outputId": "d8328490-66c1-4d7c-ccaf-19fd42102c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(854, 285)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvSwOhGmr9-a"
      },
      "outputs": [],
      "source": [
        "eras_per_chunk = 156 # 156\n",
        "eras_overlap = eras_per_chunk // 2\n",
        "purge_eras = 8  # Or 16 for 60D targets\n",
        "\n",
        "training_steps = get_training_steps(last_train_era, eras_per_chunk, purge_eras, eras_overlap, increment_start_era=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIFDs5uzuABr"
      },
      "outputs": [],
      "source": [
        "model_name = f'{MODEL_NAME}_v{MODEL_VERSION}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKi1OrGLLttS",
        "outputId": "c3f24122-eb1c-4b63-9234-f094730633f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Phases:  14%|█▍        | 2/14 [17:58<1:50:50, 554.23s/it, Train Eras=0079-0226, Purge Eras=0227-0234, Valid Eras=0235-0390, Train Corr=80.7497, Valid Corr=3.7908]"
          ]
        }
      ],
      "source": [
        "model = train_model_with_walk_forward(\n",
        "    lgb_params,\n",
        "    dataset,\n",
        "    training_steps,\n",
        "    [target_col, 'era']+features,\n",
        "    features,\n",
        "    target_col,\n",
        "    PATH_TO_MODELS,\n",
        "    model_name,\n",
        "    save_model=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFVpiVNBQ1cq"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.filter(ds.field('era').isin(teras))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pHI8ID7sHSw"
      },
      "outputs": [],
      "source": [
        "compute_and_plot_correlation_with_target(\n",
        "    model, train_dataset, [target_col, 'era']+features, features, target_col, 'train', model_name=model_name, n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOb53emCsHSx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00wkaH4qsHSx"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD4NAg5ZsHSx"
      },
      "outputs": [],
      "source": [
        "validation_dataset = dataset.filter(ds.field('era').isin(veras))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLv3-J5wsHSx"
      },
      "outputs": [],
      "source": [
        "compute_and_plot_correlation_with_target(\n",
        "    model, validation_dataset, [target_col, 'era']+features, features, target_col, 'validation', model_name=model_name, n=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLtfXjJTsHSy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrganspEsHTk"
      },
      "source": [
        "## Live data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y1IzhmjsHTk"
      },
      "outputs": [],
      "source": [
        "live_data_path = PATH_TO_DATA/ 'live.parquet'\n",
        "napi.download_dataset(f\"{DATA_VERSION}/live.parquet\", str(live_data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhgWY6DIsHTp"
      },
      "outputs": [],
      "source": [
        "live_data = pd.read_parquet(live_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcK5t8cjsHTv"
      },
      "outputs": [],
      "source": [
        "def predict(live_features: pd.DataFrame) -> pd.DataFrame:\n",
        "    live_preds = pd.DataFrame(\n",
        "        model.predict(live_features[features]),\n",
        "        index=live_features.index,\n",
        "        columns=[\"prediction\"]\n",
        "    )\n",
        "\n",
        "    neutralized = neutralize(live_preds, live_features[to_neutralize_feats], proportion=0.5)\n",
        "    return neutralized.rank(pct=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSthMTVCsHT7"
      },
      "outputs": [],
      "source": [
        "a = predict(live_data)\n",
        "a.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRWHDguosHT7"
      },
      "outputs": [],
      "source": [
        "if not TEST_RUN:\n",
        "    p = cloudpickle.dumps(predict)\n",
        "    with open(PATH_TO_PREDICT_FUNCS/f'{MODEL_NAME}_v{MODEL_VERSION}.pkl', 'wb') as f:\n",
        "        f.write(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTuAE0CqZfsT"
      },
      "outputs": [],
      "source": [
        "if not TEST_RUN:\n",
        "    model.booster_.save_model(PATH_TO_MODELS / f'lgbm_{MODEL_NAME}_v{MODEL_VERSION}.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UngnACsbztGc"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "if not TEST_RUN:\n",
        "    files.download(PATH_TO_PREDICT_FUNCS/f'{MODEL_NAME}_v{MODEL_VERSION}.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1hX4DZ4vgxp-pEVlWusj8qFfOGMRcUGl6",
      "authorship_tag": "ABX9TyPIbrvhKpKJ88mfjzX6SIs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}